"""Script for consolidating ENCODE vocab.

Flume job that consolidates all new schema vocab generated by the ENCODE
project.
"""

from __future__ import absolute_import
from __future__ import division
from __future__ import google_type_annotations
from __future__ import print_function

import logging
import google3

import apache_beam as beam

from absl import app
from absl import flags

from google3.pipeline.flume.py import runner

# Logger
LOGGER = logging.getLogger('encode_scraper')

# Where all schema files are stored
INPUT_PATTERN = '/cns/jv-d/home/datcom/encode_project/schema/*'
OUTPUT_PATH = '/cns/jv-d/home/datcom/encode_project/final_schema.txt'

# Flags
FLAGS = flags.FLAGS


class DedupWords(beam.PTransform):

  def expand(self, lines):
    return (lines
            | 'PairWithSelf' >> beam.Map(lambda x: (x.strip(), 1))
            | 'Dedup' >> beam.CombinePerKey(sum))


def dedup_words(input_pattern, output_path):
  """Deduplicates words found in schema files. """

  def pipeline(root):
    # Read the input files into a PCollection of strings, one per line.
    lines = root | 'Read' >> beam.io.ReadFromText(input_pattern)
    # Deduplicate the schema words.
    counts = lines | DedupWords()
    # Write the deduplicated words to a text file.
    (counts
     | 'Format' >> beam.Map(lambda word, formatted_word: word)
     | 'WriteToText' >> beam.io.WriteToText(output_path))

  return pipeline


def main(unused_argv):
  pipeline = dedup_words(INPUT_PATTERN, OUTPUT_PATH)
  runner.FlumeRunner().run(pipeline)


if __name__ == '__main__':
  app.run(main)
  
